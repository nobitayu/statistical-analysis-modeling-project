# YouTube视频热度预测模型构建与分析报告

## 3.2.1 建模与算法选择

### 问题背景与建模目标

本研究旨在构建一个统计模型，用于预测YouTube视频在发布后是否会成为热门（trending）视频。这是一个典型的二分类问题，目标变量为`is_trending`，取值为0（非热门）或1（热门）。该问题的实际意义在于，内容创作者和平台运营方可以在视频发布前就对其潜在热度进行预测，从而优化内容策略和资源分配。

考虑到实际应用场景，模型必须仅使用视频发布前可获得的特征进行预测，而不能依赖发布后的观看量、点赞数、评论数等后验指标。因此，我们选择了以下特征：标题长度（title_length）、标题中的问号和感叹号数量（question_exclamation_count）、标签数量（tag_count）、发布时间的小时数（hour）、标题中是否包含标签（tags_in_title）、是否为周末（is_weekend）、时间段（time_period）、视频类别（category）以及视频标题文本（title）。

### 算法选择：逻辑回归模型

在众多分类算法中，我们选择了逻辑回归（Logistic Regression）作为基础模型。这一选择基于以下几个重要考虑。

首先，逻辑回归具有良好的可解释性。逻辑回归模型通过线性组合特征并应用sigmoid函数，将线性组合映射到0到1之间的概率值。其数学表达式为：

$$P(Y=1|X) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \cdots + \beta_n X_n)}}$$

其中，$\beta_0, \beta_1, \ldots, \beta_n$是模型参数，$X_1, X_2, \ldots, X_n$是特征变量。这个公式可以改写为对数几率形式：

$$\log\left(\frac{P(Y=1|X)}{1-P(Y=1|X)}\right) = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \cdots + \beta_n X_n$$

等号左边称为对数几率（log-odds），右边是特征的线性组合。这意味着每个特征系数$\beta_i$都有明确的解释：在其他特征不变的情况下，$X_i$每增加一个单位，对数几率增加$\beta_i$，或者说，成为热门视频的几率比（odds ratio）变为原来的$e^{\beta_i}$倍。这种可解释性对于业务理解和决策制定至关重要。

其次，逻辑回归输出的是概率值而非简单的类别标签，这为后续的阈值优化提供了灵活性。在实际应用中，我们可以根据业务需求调整分类阈值，在精确率（Precision）和召回率（Recall）之间进行权衡。例如，如果业务更重视查全率（尽可能多地识别潜在热门视频），可以降低阈值；如果更重视查准率（确保预测为热门的视频确实会热门），可以提高阈值。

第三，逻辑回归计算效率高，训练和预测速度快，适合作为基线模型进行快速迭代和验证。虽然逻辑回归假设特征与目标变量之间存在线性关系，但通过适当的特征工程（如多项式特征、特征交互等），可以在一定程度上捕捉非线性模式。如果后续发现线性模型不足以捕捉数据中的复杂关系，可以在此基础上尝试更复杂的模型，如梯度提升树（XGBoost、LightGBM）或神经网络。

### 特征工程与数据预处理

由于我们的特征包含数值型、分类型和文本型三种不同类型，需要设计一个统一的预处理流程。我们采用了scikit-learn的Pipeline和ColumnTransformer机制，为不同类型的特征构建了专门的处理管道。

对于数值型特征（title_length、question_exclamation_count、tag_count、hour、tags_in_title、is_weekend），我们首先使用中位数填充缺失值。中位数相比均值对异常值更加鲁棒，能够更好地保持数据的分布特性。随后，我们使用StandardScaler进行标准化，将特征转换为均值为0、标准差为1的分布。标准化的数学公式为：

$$X_{scaled} = \frac{X - \mu}{\sigma}$$

其中$\mu$和$\sigma$分别是特征的均值和标准差。标准化的重要性在于，逻辑回归使用梯度下降等优化算法，不同尺度的特征会导致优化过程不稳定或收敛缓慢。通过标准化，所有特征都被映射到相似的数值范围，有助于模型训练的稳定性和收敛速度。

对于分类型特征（time_period、category），我们使用OneHotEncoder进行独热编码。独热编码将每个类别转换为一个二进制向量，其中只有一个位置为1，其余为0。例如，如果有三个时间段（dawn、morning、afternoon），则dawn编码为[1,0,0]，morning编码为[0,1,0]，afternoon编码为[0,0,1]。这种编码方式避免了类别之间的顺序关系，使得模型能够平等地对待每个类别。

文本特征（title）的处理最为复杂。我们首先使用TF-IDF（Term Frequency-Inverse Document Frequency）向量化器将文本转换为数值向量。TF-IDF的计算公式为：

$$TF\text{-}IDF(t,d) = TF(t,d) \times IDF(t) = \frac{f_{t,d}}{\sum_{t' \in d} f_{t',d}} \times \log\frac{N}{df_t}$$

其中，$TF(t,d)$是词项$t$在文档$d$中的词频，$IDF(t)$是逆文档频率，$N$是文档总数，$df_t$是包含词项$t$的文档数。TF-IDF能够突出在特定文档中频繁出现但在整个语料库中不常见的词，这些词往往具有更强的区分能力。我们设置max_features=2000，只保留TF-IDF值最高的2000个特征，并使用ngram_range=(1,2)同时考虑单词和双词组合（bigram），以捕捉更多的语义信息。

然而，TF-IDF向量通常是高维稀疏的，直接用于逻辑回归可能导致维度灾难和过拟合。因此，我们使用TruncatedSVD（截断奇异值分解）将2000维的TF-IDF向量降维到50维。SVD的数学原理是将原始矩阵$X$分解为：

$$X = U \Sigma V^T$$

其中$U$和$V$是正交矩阵，$\Sigma$是对角矩阵，对角线上的元素是奇异值。TruncatedSVD只保留前$k$个最大的奇异值及其对应的向量，从而将数据从高维空间投影到低维空间，同时尽可能保留原始数据的主要信息。降维不仅减少了计算复杂度，还通过去除噪声提高了模型的泛化能力。

### 模型训练与超参数优化

我们将所有预处理步骤和分类器组合成一个完整的Pipeline，确保在交叉验证和测试时，预处理步骤只基于训练数据拟合，避免数据泄露。数据按照80:20的比例划分为训练集和测试集，并使用分层抽样（stratify=y）确保训练集和测试集中正负样本的比例与原始数据一致。

在模型训练阶段，我们使用GridSearchCV进行超参数优化。逻辑回归的主要超参数是正则化强度$C$，它是L2正则化项的倒数。正则化的目的是防止过拟合，通过在损失函数中加入参数大小的惩罚项：

$$L = -\sum_{i=1}^{n} [y_i \log(p_i) + (1-y_i)\log(1-p_i)] + \frac{1}{2C}\sum_{j=1}^{m}\beta_j^2$$

其中第一项是交叉熵损失，第二项是L2正则化项。$C$值越大，正则化越弱，模型越复杂，可能过拟合；$C$值越小，正则化越强，模型越简单，可能欠拟合。我们在网格[0.01, 0.1, 1, 10]中搜索最优的$C$值，使用5折分层交叉验证（StratifiedKFold），并以ROC-AUC作为评估指标。ROC-AUC（Receiver Operating Characteristic Area Under Curve）衡量模型区分正负样本的能力，取值范围为0到1，值越大表示模型性能越好。最终，GridSearchCV选择了在交叉验证集上ROC-AUC最高的模型参数。

### 模型变体：不使用文本特征的简化版本

为了评估文本特征对模型性能的贡献，我们还构建了一个不使用文本特征的简化版本。该版本仅使用数值特征和类别特征，完全移除了标题文本的TF-IDF和SVD处理。这个简化模型具有以下特点：

- **特征数量**: 从约76个减少到26个（6个数值特征 + 20个类别特征）
- **模型复杂度**: 显著降低，训练和预测速度更快
- **可解释性**: 进一步提升，所有特征都有明确的业务含义
- **应用场景**: 适合对可解释性要求高、计算资源有限的场景

通过对比完整模型和简化模型的性能，我们可以量化文本特征对预测准确性的贡献，这对于理解模型的关键因素和实际应用具有重要意义。

## 3.2.2 模型评估与优化

### 评估指标体系

模型评估是机器学习流程中的关键环节，它帮助我们理解模型的性能表现，识别模型的优势和不足。对于二分类问题，我们采用了多个互补的评估指标，从不同角度全面评估模型性能。

准确率（Accuracy）是最直观的指标，表示正确预测的样本占总样本的比例：

$$\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}$$

其中，TP（True Positive）是真阳性，TN（True Negative）是真阴性，FP（False Positive）是假阳性，FN（False Negative）是假阴性。然而，在类别不平衡的数据集中，准确率可能会产生误导。例如，如果数据集中90%的样本是负类，一个总是预测负类的模型也能达到90%的准确率，但这显然不是一个有用的模型。

精确率（Precision）和召回率（Recall）提供了更细致的性能视角。精确率衡量的是在所有预测为正类的样本中，真正为正类的比例：

$$\text{Precision} = \frac{TP}{TP + FP}$$

召回率衡量的是在所有真正的正类样本中，被正确预测为正类的比例：

$$\text{Recall} = \frac{TP}{TP + FN}$$

在我们的应用场景中，精确率反映了模型预测为热门的视频中，真正成为热门的比例；召回率反映了所有热门视频中，被模型成功识别的比例。这两个指标往往存在权衡关系：提高召回率（降低阈值，预测更多样本为正类）通常会降低精确率（因为会引入更多假阳性），反之亦然。

F1分数是精确率和召回率的调和平均数，提供了一个平衡的单一指标：

$$F1 = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$$

F1分数对精确率和召回率都给予同等重视，适合在两者都重要的场景中使用。

ROC-AUC（Area Under the ROC Curve）是另一个重要的评估指标。ROC曲线以假阳性率（False Positive Rate, FPR）为横轴，真阳性率（True Positive Rate, TPR，即召回率）为纵轴，描绘了不同阈值下模型的性能。AUC值表示ROC曲线下的面积，取值范围为0到1。AUC=0.5表示模型性能等同于随机猜测，AUC=1.0表示完美分类器。AUC的优势在于它不依赖于特定的分类阈值，衡量的是模型整体的判别能力。

### 完整模型（使用文本特征）的性能

使用默认阈值0.5，我们的完整逻辑回归模型（包含文本特征）在测试集上取得了以下性能：准确率为0.9066，精确率为0.8553，召回率为0.9788，F1分数为0.9129，ROC-AUC为0.9631。这些结果表明模型具有优秀的判别能力，特别是0.9631的AUC值表明模型能够很好地区分热门和非热门视频。

然而，我们注意到召回率（0.9788）高于精确率（0.8553），这意味着模型倾向于预测更多样本为正类。这可能是因为模型在训练过程中学习到的决策边界使得正类样本的概率分布整体较高。在实际应用中，我们可能需要根据业务需求调整这个平衡。

### 简化模型（不使用文本特征）的性能

为了评估文本特征的重要性，我们训练了一个不使用文本特征的简化模型。该模型仅使用6个数值特征和2个类别特征，总共26个特征。在默认阈值0.5下，简化模型的性能指标为：准确率0.8460，精确率0.8067，召回率0.9100，F1分数0.8553，ROC-AUC 0.9174。

虽然简化模型的性能略低于完整模型，但仍然取得了不错的成绩。这表明结构化特征（数值和类别）本身也具有一定的预测能力。通过对比两个模型的性能，我们可以量化文本特征的贡献：

| 指标 | 不使用文本特征 | 使用文本特征 | 提升 |
|:---|:---:|:---:|:---:|
| Accuracy | 0.8460 | 0.9066 | +7.16% |
| Precision | 0.8067 | 0.8553 | +6.02% |
| Recall | 0.9100 | 0.9788 | +7.56% |
| F1 Score | 0.8553 | 0.9129 | +6.73% |
| ROC AUC | 0.9174 | 0.9631 | +4.98% |

从表中可以看出，文本特征的加入显著提升了模型性能，特别是召回率提升了7.56%，F1分数提升了6.73%。这充分说明了标题文本内容是预测视频热度的最重要因素。

### 阈值优化策略

分类阈值的选择对模型性能有重要影响。默认情况下，逻辑回归使用0.5作为阈值：如果预测概率大于等于0.5，则预测为正类，否则预测为负类。然而，0.5并不总是最优选择，特别是在类别不平衡或误分类代价不对称的情况下。

为了找到最优阈值，我们实现了一个系统化的阈值搜索方法。我们在0到1之间均匀采样101个阈值，对每个阈值计算精确率、召回率、F1分数、准确率、平衡准确率和Youden指数等指标。Youden指数定义为：

$$J = \text{TPR} - \text{FPR} = \text{Recall} - (1 - \text{Specificity})$$

其中特异性（Specificity）是真阴性率：$\text{Specificity} = \frac{TN}{TN + FP}$。Youden指数衡量的是真阳性率和假阳性率之间的差异，值越大表示模型在该阈值下的综合性能越好。

通过可视化不同阈值下的指标变化，我们发现精确率和召回率之间存在明显的权衡关系：随着阈值从0增加到1，精确率逐渐提高（因为只预测高置信度的正类），召回率逐渐降低（因为漏掉了更多真正的正类）。F1分数在某个阈值处达到最大值，这个阈值就是在F1优化目标下的最优阈值。

### 完整模型的阈值优化结果

经过阈值优化，我们发现当阈值从0.5降低到0.39时，完整模型在F1分数上取得了最佳性能。优化后的指标对比如下：

| 指标 | 优化前 (阈值=0.5) | 优化后 (阈值=0.39) | 变化 |
|:---|:---:|:---:|:---:|
| 准确率 | 0.9068 | 0.9066 | -0.0002 |
| 精确率 | 0.8758 | 0.8553 | -0.0205 |
| 召回率 | 0.9480 | 0.9788 | **+0.0308** |
| F1分数 | 0.9105 | 0.9129 | **+0.0024** |
| AUC值 | 0.9631 | 0.9631 | 0.0000 |

从结果可以看出，优化后召回率从0.9480提升到0.9788，提升了3.08个百分点，这是一个显著的改进。这意味着模型现在能够识别出更多的热门视频，减少了漏报（False Negative）。同时，精确率从0.8758下降到0.8553，下降了2.05个百分点，说明模型预测为热门的视频中，真正成为热门的比例略有下降，即假阳性（False Positive）略有增加。然而，F1分数从0.9105提升到0.9129，表明在精确率和召回率的综合平衡上，优化后的模型表现更好。

### 简化模型的阈值优化结果

对于不使用文本特征的简化模型，我们同样进行了阈值优化。经过搜索，发现最优阈值为0.43（基于F1分数优化）。优化前后的对比结果如下：

| 指标 | 优化前 (阈值=0.5) | 优化后 (阈值=0.43) | 变化 |
|:---|:---:|:---:|:---:|
| 准确率 | 0.8506 | 0.8454 | -0.0052 |
| 精确率 | 0.8098 | 0.7797 | -0.0301 |
| 召回率 | 0.9164 | 0.9628 | **+0.0464** |
| F1分数 | 0.8598 | 0.8616 | **+0.0018** |
| AUC值 | 0.9217 | 0.9217 | 0.0000 |

优化后召回率从0.9164提升到0.9628，提升了4.64个百分点，这是一个显著的改进。F1分数从0.8598提升到0.8616，提升了0.18个百分点。虽然提升幅度较小，但这是在精确率和召回率之间取得更好平衡的结果。

### 优化效果的业务意义

阈值优化的实际意义在于，它允许我们根据业务需求调整模型的预测行为。在我们的场景中，优化后的阈值更适合重视查全率的业务场景。例如，如果平台希望尽可能多地识别潜在的热门视频，以便提前进行资源分配或推广，那么较高的召回率（完整模型97.88%，简化模型96.28%）是有价值的。虽然这会导致一些非热门视频被误判为热门（精确率下降），但通过后续的人工审核或A/B测试，可以进一步筛选出真正有价值的内容。

另一方面，如果业务更重视精确率，例如在推荐系统中，误推荐非热门视频给用户可能会影响用户体验，那么可以使用更高的阈值（如0.5或更高）。通过我们的阈值搜索工具，业务方可以根据实际成本和收益，灵活选择最适合的阈值。

## 3.3 模型的解读与实际应用分析

### 模型参数的意义

逻辑回归模型的核心在于其参数（系数）$\beta_i$，这些参数揭示了不同特征对视频成为热门概率的影响方向和强度。通过分析训练好的模型，我们提取了所有特征的系数值，包括截距项。

#### 完整模型的参数分析

完整模型（使用文本特征）包含76个特征，其中文本特征通过TF-IDF和SVD降维后形成了50个潜在语义维度。分析结果显示，文本特征对模型的影响最为显著，前20个最重要的特征中有17个是文本维度，这充分说明了标题文本内容在预测视频热度中的关键作用。

最重要的文本维度是text_svd_11，系数为-9.9911，绝对值接近10，是所有特征中影响最大的。这个维度捕捉了某些特定的语义模式，这些模式与视频成为热门的概率呈强烈的负相关。text_svd_6的系数为-8.9280，text_svd_1的系数为-7.7198，都是负值且绝对值很大，表明这些语义维度捕捉到的文本模式往往与低热度相关。

另一方面，text_svd_7的系数为6.8419，text_svd_33的系数为6.4963，text_svd_8的系数为5.2807，都是正值且较大，表明这些语义维度捕捉到的文本模式与高热度相关。这些维度可能捕捉了热门视频标题中常见的表达方式、关键词组合或语言风格。

文本特征的平均系数绝对值为2.72，远高于数值特征（0.98）和类别特征（1.02），这进一步证实了标题文本内容是预测视频热度的最重要因素。模型通过SVD降维，成功地从高维的TF-IDF空间中提取出了与热度相关的关键语义模式。

#### 简化模型的参数分析

简化模型（不使用文本特征）包含26个特征，所有特征都有明确的业务含义，这使得模型参数的解释更加直观。

**数值特征的影响**：

在6个数值特征中，标签数量（tag_count）具有最大的影响，系数为-1.9479。这个负系数表明，在其他条件相同的情况下，标签数量越多，视频成为热门的概率越低。这可能是因为过度使用标签可能被视为垃圾信息或过度营销，反而降低了视频的吸引力。标题中包含标签（tags_in_title）的系数为-1.5073，同样为负，进一步支持了这一解释。

发布时间的小时数（hour）系数为0.2859，为正值，表明在一天中的某些时段发布可能更有利于视频成为热门。问号和感叹号数量（question_exclamation_count）的系数为0.0950，为正值但较小，表明适度的标题情感表达可能有助于吸引注意力。标题长度（title_length）的系数为-0.2453，为负值但影响较小，可能表明过长的标题反而会降低吸引力。是否为周末（is_weekend）的系数为0.0808，为正值但很小，表明周末发布对热门概率的影响有限。

**类别特征的影响**：

在20个类别特征中，影响最大的是"People & Blogs"类别，系数为-1.3830，表明个人博客类别较难成为热门。这可能是因为个人博客内容可能缺乏专业性和吸引力，或者与数据集中该类别的样本特征有关。

相反，"Gaming"（游戏）类别的系数为1.2166，为正值且较大，表明游戏内容更容易成为热门。这可能反映了游戏内容在YouTube平台上的实际受欢迎程度。"Music"（音乐）类别的系数为0.9332，同样为正值且较大，表明音乐内容在平台上具有较高的热度潜力。"News & Politics"（新闻与政治）类别的系数为0.7146，也为正值，反映了新闻内容往往具有时效性和话题性，容易引发讨论和分享。

在时间段方面，"morning"（早晨）时段的系数为-1.0137，为负值，表明早晨发布的视频成为热门的概率较低。这可能是因为早晨时段的用户活跃度相对较低，或者与数据集中早晨时段视频的实际表现有关。相反，"dawn"（黎明）时段的系数为0.6645，为正值，表明黎明时段发布可能更有利于视频获得关注。

### 参数解释的实际意义

从模型参数的分析中，我们可以得出几个重要的业务洞察。首先，标题内容是最重要的预测因素（在完整模型中），创作者应该重视标题的撰写，选择能够吸引目标受众的表达方式和关键词。其次，视频类别对热度有显著影响，某些类别（如游戏、音乐、新闻）更容易成为热门，而其他类别（如个人博客、教育）可能需要更多的推广努力。第三，标签的使用需要适度，过度使用标签可能适得其反。第四，发布时间虽然有一定影响，但影响相对较小，内容质量可能比发布时间更重要。

这些发现为内容创作者和平台运营方提供了有价值的指导，帮助他们优化内容策略和提高视频的热门概率。

### 实际应用场景

模型的实际应用可以分为几个主要场景。首先是内容创作辅助。视频创作者可以在发布视频前，输入视频的标题、类别、发布时间等信息，模型会输出该视频成为热门的概率。如果概率较高（例如大于优化后的阈值0.39或0.43），创作者可以更有信心地投入更多资源进行推广；如果概率较低，创作者可以考虑优化标题、调整发布时间或选择不同的类别标签。

第二个应用场景是平台资源分配。视频平台可以在视频上传后、正式发布前，使用模型预测其热度潜力。对于预测为高热度的视频，平台可以提前分配更多的服务器资源、推荐位资源或推广资源，确保在视频真正热门时能够提供流畅的用户体验。

第三个应用场景是内容审核和推荐系统的前置筛选。在内容审核流程中，模型可以帮助识别可能需要优先审核的高潜力内容。在推荐系统中，模型可以作为冷启动阶段的辅助工具，为新上传的视频提供初始的热度估计。

### 模型应用的实现

我们实现了一个`predict_unpublished`函数，该函数接受包含必要特征的字典或DataFrame，返回预测概率和预测标签。函数的使用非常简单：

```python
# 示例：预测单个视频
video_info = {
    'title': 'How to Learn Machine Learning in 2024',
    'title_length': 35,
    'question_exclamation_count': 0,
    'tag_count': 5,
    'hour': 14,
    'tags_in_title': 0,
    'is_weekend': 0,
    'time_period': 'afternoon',
    'category': 'Education'
}

result = predict_unpublished(video_info)
print(f"成为热门的概率: {result['pred_prob_trending'][0]:.4f}")
print(f"预测结果: {'热门' if result['pred_is_trending'][0] == 1 else '非热门'}")
```

从我们的示例预测结果中可以看到，模型对不同视频给出了不同的预测概率。例如，一个标题为"I Survived 100 Days in the Multiverse on Hardcore Minecraft"的游戏类视频，模型预测其成为热门的概率高达0.9976，这反映了模型学习到的模式：长标题、游戏类别、下午发布等因素的组合与高热度相关。相反，一个标题为"phonetic Transcription"的教育类视频，预测概率仅为0.1701，表明这类内容的热度潜力较低。

### 模型的局限性与改进方向

尽管模型在测试集上表现良好，但我们需要注意几个重要的局限性。首先，模型是基于历史数据训练的，它学习的是历史数据中的模式。如果视频平台的用户行为、内容趋势或算法推荐机制发生变化，模型的性能可能会下降。因此，模型需要定期重新训练，以保持与当前数据分布的匹配。

其次，模型仅使用了发布前可获得的特征，这些特征的信息量有限。实际上，视频的热度还受到许多其他因素的影响，如视频质量、创作者影响力、当前热点话题、平台算法变化等，这些因素在发布前难以量化。因此，模型的预测存在固有的不确定性。

第三，逻辑回归作为线性模型，可能无法捕捉特征之间的复杂交互关系。例如，标题长度和类别之间可能存在交互效应：对于某些类别，长标题可能更受欢迎，而对于其他类别，短标题可能更好。虽然TF-IDF的bigram特征在一定程度上捕捉了文本中的局部交互，但数值特征和类别特征之间的交互可能需要显式建模。

针对这些局限性，未来的改进方向包括：引入更多特征（如创作者历史表现、视频描述文本、缩略图特征等）、尝试非线性模型（如梯度提升树、神经网络）、实现在线学习机制以持续适应数据分布变化、以及引入不确定性量化方法（如贝叶斯逻辑回归）来估计预测的置信区间。

### 模型选择建议

根据实际应用需求，我们提供以下模型选择建议：

**选择完整模型（使用文本特征）的场景**：
- 需要最高的预测准确性
- 计算资源充足
- 可以接受模型的可解释性相对较低
- 标题文本信息可获得

**选择简化模型（不使用文本特征）的场景**：
- 对模型可解释性要求高
- 计算资源有限
- 标题文本信息不可获得或不可靠
- 需要快速部署和迭代

**阈值选择建议**：
- 重视查全率：使用较低阈值（完整模型0.39，简化模型0.43）
- 重视查准率：使用较高阈值（0.5或更高）
- 平衡精确率和召回率：使用优化后的阈值（完整模型0.39，简化模型0.43）

## 结论

本研究成功构建了基于逻辑回归的YouTube视频热度预测模型，包括完整版本（使用文本特征）和简化版本（不使用文本特征）。通过系统的特征工程、超参数优化和阈值调整，两个模型都取得了良好的性能：

- **完整模型**：AUC=0.9631，F1=0.9129，准确率=0.9066
- **简化模型**：AUC=0.9174，F1=0.8616，准确率=0.8460

通过阈值优化，我们进一步提升了模型性能，特别是召回率得到了显著提升。模型具有良好的可解释性和实用性，能够为内容创作者和平台运营方提供有价值的预测信息。虽然模型存在一定的局限性，但通过持续改进和优化，可以进一步提升其在实际应用中的价值。

---

*本报告基于项目代码、评估结果和可视化图表生成。详细的代码实现、评估指标和可视化结果请参考项目目录中的相关文件。*

